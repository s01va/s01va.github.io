{"componentChunkName":"component---node-modules-gatsby-theme-portfolio-minimal-src-templates-article-index-tsx","path":"/SecuriyOnion-so-rule-modify/","result":{"pageContext":{"article":{"banner":{"alt":null,"caption":null,"src":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/75a9940ab0e221262fb877617a1286bc/86907/0.png","srcSet":"/static/75a9940ab0e221262fb877617a1286bc/448cf/0.png 128w,\n/static/75a9940ab0e221262fb877617a1286bc/3fd3a/0.png 256w,\n/static/75a9940ab0e221262fb877617a1286bc/86907/0.png 512w","sizes":"(min-width: 512px) 512px, 100vw"},"sources":[{"srcSet":"/static/75a9940ab0e221262fb877617a1286bc/75874/0.webp 128w,\n/static/75a9940ab0e221262fb877617a1286bc/f32e0/0.webp 256w,\n/static/75a9940ab0e221262fb877617a1286bc/2fc55/0.webp 512w","type":"image/webp","sizes":"(min-width: 512px) 512px, 100vw"}]},"width":660,"height":399.609375}}}},"body":"<h1>결론</h1>\n<p>룰을 sid를 기준으로 관리하며 룰 자체를 전체 수정하는 방식으로 사용하고자 한다면, disable 후 add 시키는 방식을 사용하는 것이 좋을 것 같습니다.</p>\n<p>이하는 2.3.xx 버전을 기준으로 테스트한 기록입니다. 개인적으로 얻어간 것도 있지만 결론적으로 목적 달성에 실패한 기록들이니... 궁금하신 분들만 읽어보세요</p>\n<h2>+</h2>\n<p>수리카타에서 룰을 관리할 때 작게나마 DB 등을 사용하지 않고 이렇게 파일을 복잡하게 사용하는 이유가 있는걸까요...? sid로 일괄 관리하고 싶었는데 그렇게 하려니 쉽지 않아서 아쉬웠습니다.</p>\n<h1>상황</h1>\n<p>Security onion에서의 rule control하는 부분들을 응용하여 무언가 제작할 일이 있었다. Kafka로 rule에 관련된 입력값들을 받은 후 내부적으로 SO(Security onion)을 응용해야 하는데, 기존 SO을 변형하지 않고 있는 기능을 최대한 그대로 사용하는 것이 목표였다. SO가 업데이트 될 때마다 우리가 고친 부분들이 덮어써질 것이기 때문이다.</p>\n<p>다른건 몰라도 rule modify 시에 상당히 삽질을 하게 되어서... 기록 남기려고 작성했다.</p>\n<h1>분석 및 목표설정</h1>\n<h2>Security onion side</h2>\n<p>Security onion에서 rule을 컨트롤하기 위해서는 <code class=\"language-text\">so-rule</code> 명령어를 사용한다.</p>\n<p><code class=\"language-text\">so-rule</code> 실행의 실체는 Security onion이 설치된 리눅스의 <code class=\"language-text\">/usr/sbin/</code>에 위치한 <code class=\"language-text\">so-rule</code>이라는 파이썬 파일이다<a href=\"https://github.com/Security-Onion-Solutions/securityonion/blob/3839e5240127ac3c7b7659b2a270337f859dbf5a/salt/common/tools/sbin/so-rule\">(so-rule python code)</a>.</p>\n<p>아래는 modify 동작을 최초로 인식하는 부분이다.</p>\n<p>so-rule 명령어를 사용해서 modify 내용을 추가하려면 '<code class=\"language-text\">so-rule modify add [sid] [search_term] [replace_term]</code>'와 같은 방식으로 입력해야 하는 것도 여기에 명시되어 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n<span class=\"token comment\"># Modify actions</span>\n  modify <span class=\"token operator\">=</span> subparsers<span class=\"token punctuation\">.</span>add_parser<span class=\"token punctuation\">(</span><span class=\"token string\">'modify'</span><span class=\"token punctuation\">)</span>\n  modify_sub <span class=\"token operator\">=</span> modify<span class=\"token punctuation\">.</span>add_subparsers<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n  modify_add <span class=\"token operator\">=</span> modify_sub<span class=\"token punctuation\">.</span>add_parser<span class=\"token punctuation\">(</span><span class=\"token string\">'add'</span><span class=\"token punctuation\">)</span>\n  modify_add<span class=\"token punctuation\">.</span>set_defaults<span class=\"token punctuation\">(</span>func<span class=\"token operator\">=</span>add_rem_modify<span class=\"token punctuation\">)</span>\n  modify_add<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'sid_pattern'</span><span class=\"token punctuation\">,</span> metavar<span class=\"token operator\">=</span><span class=\"token string\">'SID|REGEX'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span>sid_or_regex_help<span class=\"token punctuation\">)</span>\n  modify_add<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'search_term'</span><span class=\"token punctuation\">,</span> metavar<span class=\"token operator\">=</span><span class=\"token string\">'SEARCH_TERM'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span>search_term_help<span class=\"token punctuation\">)</span>\n  modify_add<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'replace_term'</span><span class=\"token punctuation\">,</span> metavar<span class=\"token operator\">=</span><span class=\"token string\">'REPLACE_TERM'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span>replace_term_help<span class=\"token punctuation\">)</span>\n  modify_add<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'--apply'</span><span class=\"token punctuation\">,</span> action<span class=\"token operator\">=</span><span class=\"token string\">'store_const'</span><span class=\"token punctuation\">,</span> const<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span>apply_help<span class=\"token punctuation\">)</span>\n\n  modify_rem <span class=\"token operator\">=</span> modify_sub<span class=\"token punctuation\">.</span>add_parser<span class=\"token punctuation\">(</span><span class=\"token string\">'remove'</span><span class=\"token punctuation\">)</span>\n  modify_rem<span class=\"token punctuation\">.</span>set_defaults<span class=\"token punctuation\">(</span>func<span class=\"token operator\">=</span>add_rem_modify<span class=\"token punctuation\">,</span> remove<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n  modify_rem<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'sid_pattern'</span><span class=\"token punctuation\">,</span> metavar<span class=\"token operator\">=</span><span class=\"token string\">'SID'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span>sid_or_regex_help<span class=\"token punctuation\">)</span>\n  modify_rem<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'search_term'</span><span class=\"token punctuation\">,</span> metavar<span class=\"token operator\">=</span><span class=\"token string\">'SEARCH_TERM'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span>search_term_help<span class=\"token punctuation\">)</span>\n  modify_rem<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'replace_term'</span><span class=\"token punctuation\">,</span> metavar<span class=\"token operator\">=</span><span class=\"token string\">'REPLACE_TERM'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span>replace_term_help<span class=\"token punctuation\">)</span>\n  modify_rem<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'--apply'</span><span class=\"token punctuation\">,</span> action<span class=\"token operator\">=</span><span class=\"token string\">'store_const'</span><span class=\"token punctuation\">,</span> const<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span>apply_help<span class=\"token punctuation\">)</span>\n\n  modify_list <span class=\"token operator\">=</span> modify_sub<span class=\"token punctuation\">.</span>add_parser<span class=\"token punctuation\">(</span><span class=\"token string\">'list'</span><span class=\"token punctuation\">)</span>\n  modify_list<span class=\"token punctuation\">.</span>set_defaults<span class=\"token punctuation\">(</span>func<span class=\"token operator\">=</span>list_modified_rules<span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></code></pre></div>\n<p><code class=\"language-text\">func=add_rem_modify</code>를 보아 rule 수정 내용 추가 시에 이 함수를 사용하는 것을 알 수 있다.</p>\n<p>아래는 같은 소스코드에 존재하는 <code class=\"language-text\">add_rem_modify</code> 함수이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">add_rem_modify</span><span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">:</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">global</span> salt_proc\n\n  <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> check_sid_pattern<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">.</span>sid_pattern<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">2</span>\n\n  <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> valid_regex<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">.</span>search_term<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    print_err<span class=\"token punctuation\">(</span><span class=\"token string\">'Search term is not a valid regex pattern.'</span><span class=\"token punctuation\">)</span>\n\n  string_val <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>args<span class=\"token punctuation\">.</span>sid_pattern<span class=\"token punctuation\">}</span></span><span class=\"token string\"> \\\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>args<span class=\"token punctuation\">.</span>search_term<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\\" \\\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>args<span class=\"token punctuation\">.</span>replace_term<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\\"'</span></span>\n\n  pillar_dict <span class=\"token operator\">=</span> read_pillar<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">.</span>pillar<span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> sids_key_exists<span class=\"token punctuation\">(</span>pillar_dict<span class=\"token punctuation\">,</span> <span class=\"token string\">'modify'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    pillar_dict<span class=\"token punctuation\">[</span><span class=\"token string\">'idstools'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sids'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'modify'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n\n  <span class=\"token keyword\">if</span> args<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">:</span>\n    temp_pillar_dict <span class=\"token operator\">=</span> rem_from_sids<span class=\"token punctuation\">(</span>pillar_dict<span class=\"token punctuation\">,</span> <span class=\"token string\">'modify'</span><span class=\"token punctuation\">,</span> string_val<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n    temp_pillar_dict <span class=\"token operator\">=</span> add_to_sids<span class=\"token punctuation\">(</span>pillar_dict<span class=\"token punctuation\">,</span> <span class=\"token string\">'modify'</span><span class=\"token punctuation\">,</span> string_val<span class=\"token punctuation\">)</span>\n    \n  <span class=\"token keyword\">if</span> temp_pillar_dict<span class=\"token punctuation\">[</span><span class=\"token string\">'idstools'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sids'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'modify'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> pillar_dict<span class=\"token punctuation\">[</span><span class=\"token string\">'idstools'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sids'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'modify'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    salt_proc <span class=\"token operator\">=</span> check_apply<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">,</span> prompt<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> salt_proc\n  <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n    pillar_dict <span class=\"token operator\">=</span> temp_pillar_dict\n\n  <span class=\"token comment\"># TODO: Determine if a rule should be removed from disabled if modified.</span>\n  <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> args<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> sids_key_exists<span class=\"token punctuation\">(</span>pillar_dict<span class=\"token punctuation\">,</span> <span class=\"token string\">'disabled'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n      pillar_dict <span class=\"token operator\">=</span> rem_from_sids<span class=\"token punctuation\">(</span>pillar_dict<span class=\"token punctuation\">,</span> <span class=\"token string\">'disabled'</span><span class=\"token punctuation\">,</span> args<span class=\"token punctuation\">.</span>sid_pattern<span class=\"token punctuation\">,</span> optional<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> \n\n  write_pillar<span class=\"token punctuation\">(</span>pillar<span class=\"token operator\">=</span>args<span class=\"token punctuation\">.</span>pillar<span class=\"token punctuation\">,</span> content<span class=\"token operator\">=</span>pillar_dict<span class=\"token punctuation\">)</span>\n  \n  salt_proc <span class=\"token operator\">=</span> check_apply<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> salt_proc\n  </code></pre></div>\n<p>sid와 search_term에 대해 regex 문법 체크를 한 후, search_term과 replace_term에 대해 escape 처리된 double quotes로 감싸서 처리되고 있다.</p>\n<p>sid로 검색해서 나온 <strong>rule 전문에 대해 덮어쓰기를 하는 방식을 기대</strong>했지만, 여기까지만 봐도 그런 방식이 아님을 알 수 있다. <strong>search_term을 regex로 검색한 후 이를 전부 replace_term으로 교체</strong>하는 방식이다. 하지만 여러 문자열이 아닌 짧은 문자열에 대해 교체하고자 할 때, 이와 같은 방식이 유지된다면 사용자가 원하던 것과는 다른 rule 수정이 일어날 수도 있다고 보았다. 짧은 문자열일수록 원하지 않던 곳에 문자열 대체가 일어날 확률이 높아지기 때문이다.</p>\n<p>그러나 우리의 목적은 기존의 SO에는 변경을 가하지 않는 것이었기 때문에, search_term에 rule 전문을 잘 우겨넣어 인자로 잘 전 전달하는 방법을 찾아야 했다.</p>\n<p>이제부터 이 아래는 그 삽질기이다...</p>\n<p>위의 <code class=\"language-text\">add_rem_modify</code> 함수에서 알게 된 것은 두가지이다.</p>\n<ol>\n<li>double quotes(\")를 escape처리 해야 search_term이 한 덩어리의 string으로 온전하게 들어감(rule의 msg 부분에 거의 대부분 double quotes(\")가 들어가기 때문에, msg 부분에서 문자열이 잘릴 수도 있다)</li>\n<li>regex escape처리가 되어야 중간에 에러가 걸리지 않음</li>\n</ol>\n<p>그래서 대강 이런 식의 escape 처리 후 command 입력을 시도했다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n<span class=\"token keyword\">import</span> re\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n<span class=\"token comment\"># Kafka에서 참조한 sid, new_rule_raw / DB에서 참조해 온 old_rule_raw</span>\nold_rule <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>escape<span class=\"token punctuation\">(</span>old_rule_raw<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'\"'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'\\\\\"'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nnew_rule <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>escape<span class=\"token punctuation\">(</span>new_rule_raw<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'\"'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'\\\\\"'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ncommand_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n  <span class=\"token string-interpolation\"><span class=\"token string\">f\"so-rule modify add </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>sid<span class=\"token punctuation\">}</span></span><span class=\"token string\"> '</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>old_rule<span class=\"token punctuation\">}</span></span><span class=\"token string\">' '</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>new_rule<span class=\"token punctuation\">}</span></span><span class=\"token string\">' --apply\"</span></span>\n<span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></code></pre></div>\n<p>두 escape 처리 이전까지 뜨던 각종 bash 오류들(ex. unexpected token)이 사라져 순조롭게 진행되는 듯 했으나, stdout으로 또다른 문제에 직면했음을 알 수 있었다.</p>\n<h2>idstools(suricata) side</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"> Configuration updated. Applying changes:, \n Syncing config files<span class=\"token punctuation\">..</span>., \n Updating rules<span class=\"token punctuation\">..</span>., \n <span class=\"token number\">2023</span>-11-01 06:59:13,009 - <span class=\"token operator\">&lt;</span>INFO<span class=\"token operator\">></span> - Loading ./rulecat.conf., \n <span class=\"token number\">2023</span>-11-01 06:59:13,012 - <span class=\"token operator\">&lt;</span>INFO<span class=\"token operator\">></span> - Forcing Suricata version to <span class=\"token number\">6.0</span>., \n Traceback <span class=\"token punctuation\">(</span>most recent call last<span class=\"token punctuation\">)</span>:, \n   File <span class=\"token string\">\"/usr/local/bin/idstools-rulecat\"</span>, line <span class=\"token number\">12</span>, <span class=\"token keyword\">in</span> <span class=\"token operator\">&lt;</span>module<span class=\"token operator\">></span>, \n     sys.exit<span class=\"token punctuation\">(</span>main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span>, \n   File <span class=\"token string\">\"/usr/local/lib/python3.9/site-packages/idstools/scripts/rulecat.py\"</span>, line <span class=\"token number\">841</span>, <span class=\"token keyword\">in</span> main, \n     modify_filters <span class=\"token operator\">+=</span> load_filters<span class=\"token punctuation\">(</span>args.modify<span class=\"token punctuation\">)</span>, \n   File <span class=\"token string\">\"/usr/local/lib/python3.9/site-packages/idstools/scripts/rulecat.py\"</span>, line <span class=\"token number\">375</span>, <span class=\"token keyword\">in</span> load_filters, \n     filter <span class=\"token operator\">=</span> ModifyRuleFilter.parse<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span>, \n   File <span class=\"token string\">\"/usr/local/lib/python3.9/site-packages/idstools/scripts/rulecat.py\"</span>, line <span class=\"token number\">218</span>, <span class=\"token keyword\">in</span> parse, \n     raise Exception<span class=\"token punctuation\">(</span><span class=\"token string\">\"Bad number of arguments.\"</span><span class=\"token punctuation\">)</span>, \n Exception: Bad number of arguments.</code></pre></div>\n<p>so-rule을 실행하는 데 까지 생기는 문제는 해결한 것 같다. 하지만 이제는 명령어 실행 중 내부에서 문제가 생기는 것 같다.</p>\n<p>manager sls파일(<code class=\"language-text\">/opt/so/saltstack/local/pillar/minion/[host_manager].sls</code>) modify 항목에 잘 입력된 것을 확인했다. 즉 modify 과정은 2 step 이었던 것이다.</p>\n<ol>\n<li>manager 파일에 rule의 sid와 함께 modify 내역을 기록</li>\n<li>이 기록을 바탕으로 실제 rule modify 진행</li>\n</ol>\n<p>1까지는 성공적이었으나 2 과정 중에서 문제가 생기는 것으로 파악되었다.</p>\n<p>위의 문제를 해결하기 위해 <a href=\"https://github.com/jasonish/py-idstools/blob/master/idstools/scripts/rulecat.py\">rulecat.py</a>를 뜯어보았다.</p>\n<p>다음은 문제가 되는 ModifyRuleFilter.parse()를 관찰하기 위해 가져온 class이다.</p>\n<p><a href=\"https://github.com/jasonish/py-idstools/blob/master/idstools/scripts/rulecat.py#L218\"><em>rulecat.py line 218 확인</em></a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">ModifyRuleFilter</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Filter to modify an idstools rule object.\n\n    Important note: This filter does not modify the rule inplace, but\n    instead returns a new rule object with the modification.\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> matcher<span class=\"token punctuation\">,</span> pattern<span class=\"token punctuation\">,</span> repl<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>matcher <span class=\"token operator\">=</span> matcher\n        self<span class=\"token punctuation\">.</span>pattern <span class=\"token operator\">=</span> pattern\n        self<span class=\"token punctuation\">.</span>repl <span class=\"token operator\">=</span> repl\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">match</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> rule<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>matcher<span class=\"token punctuation\">.</span><span class=\"token keyword\">match</span><span class=\"token punctuation\">(</span>rule<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">filter</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> rule<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        modified_rule <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>pattern<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>repl<span class=\"token punctuation\">,</span> rule<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        parsed <span class=\"token operator\">=</span> idstools<span class=\"token punctuation\">.</span>rule<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>modified_rule<span class=\"token punctuation\">,</span> rule<span class=\"token punctuation\">.</span>group<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> parsed <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            logger<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string\">\"Modification of rule %s results in invalid rule: %s\"</span><span class=\"token punctuation\">,</span>\n                         rule<span class=\"token punctuation\">.</span>idstr<span class=\"token punctuation\">,</span> modified_rule<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span> rule\n        <span class=\"token keyword\">return</span> parsed\n\n    <span class=\"token decorator annotation punctuation\">@classmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">parse</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> buf<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        tokens <span class=\"token operator\">=</span> shlex<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>buf<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokens<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">3</span><span class=\"token punctuation\">:</span>\n            matchstring<span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">,</span> b <span class=\"token operator\">=</span> tokens\n        <span class=\"token keyword\">elif</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokens<span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">3</span> <span class=\"token keyword\">and</span> tokens<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"modifysid\"</span><span class=\"token punctuation\">:</span>\n            matchstring<span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">,</span> b <span class=\"token operator\">=</span> tokens<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> tokens<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> tokens<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">raise</span> Exception<span class=\"token punctuation\">(</span><span class=\"token string\">\"Bad number of arguments.\"</span><span class=\"token punctuation\">)</span>\n        matcher <span class=\"token operator\">=</span> parse_rule_match<span class=\"token punctuation\">(</span>matchstring<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> matcher<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">raise</span> Exception<span class=\"token punctuation\">(</span><span class=\"token string\">\"Bad match string: %s\"</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>tokens<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        pattern <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Convert Oinkmaster backticks to Python.</span>\n        b <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\$\\{(\\d+)\\}\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\\\\\\\\\\\1\"</span><span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">(</span>matcher<span class=\"token punctuation\">,</span> pattern<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span></code></pre></div>\n<p>여기서 위에서 본 \"Bad number of arguments\" 문구를 확인할 수 있었고 이의 원인이 무엇인지도 파악할 수 있었다.</p>\n<p><code class=\"language-text\">shlex.split(buf)</code> 결과물의 갯수가 기준과 맞지 않기 때문이다.</p>\n<p><code class=\"language-text\">buf</code>로 입력되는 것은 역시 위의 manager sls파일에서 읽은 modify 항목들이다.</p>\n<p><em>(rulcat.py line 375 확인)</em></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">load_filters</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    filters <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fileobj<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> fileobj<span class=\"token punctuation\">:</span>\n            line <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> line <span class=\"token keyword\">or</span> line<span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"#\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">continue</span>\n            <span class=\"token builtin\">filter</span> <span class=\"token operator\">=</span> ModifyRuleFilter<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> <span class=\"token builtin\">filter</span><span class=\"token punctuation\">:</span>\n                filters<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token builtin\">filter</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                log<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string\">\"Failed to parse modify filter: %s\"</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> filters</code></pre></div>\n<p>manager sls을 한줄씩 읽어와 <code class=\"language-text\">buf</code>로 입력하고 있다.</p>\n<p>이를 확인 후 manager sls파일에서 자동으로 modify 항목으로 입력된 값을 확인했더니, 한 row로 입력된 것이 아니라 부분부분 줄바꿈처리 되어 들어가 있었다.</p>\n<p>(테스트한 rule은 suricata ET open rule중 하나를 가져왔다.)</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token punctuation\">...</span>\n<span class=\"token key atrule\">idstools</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">...</span>\n  <span class=\"token key atrule\">sids</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">disabled</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">'0000001'</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">'0000002'</span>\n    <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">'0000003'</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">'0000004'</span>\n    <span class=\"token key atrule\">modify</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> '0000005 \"alert ip \\<span class=\"token punctuation\">[</span>1.117.107.241<span class=\"token punctuation\">,</span>1.117.113.235<span class=\"token punctuation\">,</span>1.117.142.123<span class=\"token punctuation\">,</span>1.117.155.76<span class=\"token punctuation\">,</span>1.117.233.118<span class=\"token punctuation\">,</span>1.117.87.94<span class=\"token punctuation\">,</span>1.12.220.225<span class=\"token punctuation\">,</span>1.13.5.215<span class=\"token punctuation\">,</span>1.14.101.60<span class=\"token punctuation\">,</span>1.14.162.37<span class=\"token punctuation\">,</span>1.14.170.161<span class=\"token punctuation\">,</span>1.14.63.99<span class=\"token punctuation\">,</span>1.14.72.158<span class=\"token punctuation\">,</span>1.15.112.113<span class=\"token punctuation\">,</span>1.15.119.209<span class=\"token punctuation\">,</span>1.15.155.17<span class=\"token punctuation\">,</span>1.15.48.27<span class=\"token punctuation\">,</span>1.15.94.178<span class=\"token punctuation\">,</span>1.212.197.134<span class=\"token punctuation\">,</span>1.234.80.51<span class=\"token punctuation\">,</span>1.234.80.65<span class=\"token punctuation\">,</span>1.6.52.114<span class=\"token punctuation\">,</span>1.9.78.242<span class=\"token punctuation\">,</span>101.176.32.93<span class=\"token punctuation\">,</span>101.32.127.191<span class=\"token punctuation\">,</span>101.32.141.93<span class=\"token punctuation\">,</span>101.33.232.244<span class=\"token punctuation\">,</span>101.34.0.215<span class=\"token punctuation\">,</span>101.34.103.153<span class=\"token punctuation\">,</span>101.34.211.195<span class=\"token punctuation\">,</span>101.34.246.169<span class=\"token punctuation\">,</span>101.34.67.139<span class=\"token punctuation\">,</span>101.34.69.51<span class=\"token punctuation\">,</span>101.35.181.230<span class=\"token punctuation\">,</span>101.35.19.119<span class=\"token punctuation\">,</span>101.35.219.249<span class=\"token punctuation\">,</span>101.35.232.12<span class=\"token punctuation\">,</span>101.35.252.124<span class=\"token punctuation\">,</span>101.35.255.83<span class=\"token punctuation\">,</span>101.35.98.237<span class=\"token punctuation\">,</span>101.42.0.60<span class=\"token punctuation\">,</span>101.42.154.35<span class=\"token punctuation\">,</span>101.42.234.70<span class=\"token punctuation\">,</span>101.42.237.207<span class=\"token punctuation\">,</span>101.42.47.78<span class=\"token punctuation\">,</span>101.43.155.178<span class=\"token punctuation\">,</span>101.43.19.142<span class=\"token punctuation\">,</span>101.43.226.18<span class=\"token punctuation\">,</span>101.43.5.247<span class=\"token punctuation\">,</span>101.43.67.29\\<span class=\"token punctuation\">]</span>\n      any <span class=\"token punctuation\">-</span><span class=\"token punctuation\">></span>  any \\(msg<span class=\"token punctuation\">:</span>\"ET 3CORESec Poor Reputation IP group 1\"; reference<span class=\"token punctuation\">:</span>url<span class=\"token punctuation\">,</span>blacklist.3coresec.net/lists/et<span class=\"token punctuation\">-</span>open.txt;\n      <span class=\"token key atrule\">threshold</span><span class=\"token punctuation\">:</span> type limit<span class=\"token punctuation\">,</span> track by_src<span class=\"token punctuation\">,</span> seconds 3600<span class=\"token punctuation\">,</span> count 1; classtype<span class=\"token punctuation\">:</span>misc<span class=\"token punctuation\">-</span>attack;\n      sid<span class=\"token punctuation\">:</span>0000005; rev<span class=\"token punctuation\">:</span>855; metadata<span class=\"token punctuation\">:</span>affected_product Any<span class=\"token punctuation\">,</span> attack_target Any<span class=\"token punctuation\">,</span> deployment\n      Perimeter<span class=\"token punctuation\">,</span> tag 3CORESec<span class=\"token punctuation\">,</span> signature_severity Major<span class=\"token punctuation\">,</span> created_at 2020_07_20<span class=\"token punctuation\">,</span> updated_at\n      2023_10_30;\\)\" \"alert ip \\<span class=\"token punctuation\">[</span>1.117.107.241<span class=\"token punctuation\">,</span>1.117.113.235<span class=\"token punctuation\">,</span>1.117.142.123<span class=\"token punctuation\">,</span>1.117.155.76<span class=\"token punctuation\">,</span>1.117.233.118<span class=\"token punctuation\">,</span>1.117.87.94<span class=\"token punctuation\">,</span>1.12.220.225<span class=\"token punctuation\">,</span>1.13.5.215<span class=\"token punctuation\">,</span>1.14.101.60<span class=\"token punctuation\">,</span>1.14.162.37<span class=\"token punctuation\">,</span>1.14.170.161<span class=\"token punctuation\">,</span>1.14.63.99<span class=\"token punctuation\">,</span>1.14.72.158<span class=\"token punctuation\">,</span>1.15.112.113<span class=\"token punctuation\">,</span>1.15.119.209<span class=\"token punctuation\">,</span>1.15.155.17<span class=\"token punctuation\">,</span>1.15.48.27<span class=\"token punctuation\">,</span>1.15.94.178<span class=\"token punctuation\">,</span>1.212.197.134<span class=\"token punctuation\">,</span>1.234.80.51<span class=\"token punctuation\">,</span>1.234.80.65<span class=\"token punctuation\">,</span>1.6.52.114<span class=\"token punctuation\">,</span>1.9.78.242<span class=\"token punctuation\">,</span>101.176.32.93<span class=\"token punctuation\">,</span>101.32.127.191<span class=\"token punctuation\">,</span>101.32.141.93<span class=\"token punctuation\">,</span>101.33.232.244<span class=\"token punctuation\">,</span>101.34.0.215<span class=\"token punctuation\">,</span>101.34.103.153<span class=\"token punctuation\">,</span>101.34.211.195<span class=\"token punctuation\">,</span>101.34.246.169<span class=\"token punctuation\">,</span>101.34.67.139<span class=\"token punctuation\">,</span>101.34.69.51<span class=\"token punctuation\">,</span>101.35.181.230<span class=\"token punctuation\">,</span>101.35.19.119<span class=\"token punctuation\">,</span>101.35.219.249<span class=\"token punctuation\">,</span>101.35.232.12<span class=\"token punctuation\">,</span>101.35.252.124<span class=\"token punctuation\">,</span>101.35.255.83<span class=\"token punctuation\">,</span>101.35.98.237<span class=\"token punctuation\">,</span>101.42.0.60<span class=\"token punctuation\">,</span>101.42.154.35<span class=\"token punctuation\">,</span>101.42.234.70<span class=\"token punctuation\">,</span>101.42.237.207<span class=\"token punctuation\">,</span>101.42.47.78<span class=\"token punctuation\">,</span>101.43.155.178<span class=\"token punctuation\">,</span>101.43.19.142<span class=\"token punctuation\">,</span>101.43.226.18<span class=\"token punctuation\">,</span>101.43.5.247<span class=\"token punctuation\">,</span>101.43.67.29\\<span class=\"token punctuation\">]</span>\n      any <span class=\"token punctuation\">-</span><span class=\"token punctuation\">></span>  any \\(msg<span class=\"token punctuation\">:</span>\"<span class=\"token comment\">###LINE FEED TEST### ET 3CORESec Poor Reputation IP group</span>\n      1\"; reference<span class=\"token punctuation\">:</span>url<span class=\"token punctuation\">,</span><span class=\"token key atrule\">blacklist.3coresec.net/lists/et-open.txt; threshold</span><span class=\"token punctuation\">:</span> type\n      limit<span class=\"token punctuation\">,</span> track by_src<span class=\"token punctuation\">,</span> seconds 3600<span class=\"token punctuation\">,</span> count 1; classtype<span class=\"token punctuation\">:</span>misc<span class=\"token punctuation\">-</span>attack; sid<span class=\"token punctuation\">:</span>0000005;\n      rev<span class=\"token punctuation\">:</span>855; metadata<span class=\"token punctuation\">:</span>affected_product Any<span class=\"token punctuation\">,</span> attack_target Any<span class=\"token punctuation\">,</span> deployment Perimeter<span class=\"token punctuation\">,</span>\n      tag 3CORESec<span class=\"token punctuation\">,</span> signature_severity Major<span class=\"token punctuation\">,</span> created_at 2020_07_20<span class=\"token punctuation\">,</span> updated_at 2023_10_30;\\)\"'\n    <span class=\"token punctuation\">-</span> '0000006'<span class=\"token punctuation\">...</span>\n<span class=\"token punctuation\">...</span></code></pre></div>\n<p>이전 과정에서 <code class=\"language-text\">re.escape(str_raw.replace('\"', '\\\\\"'))</code>로 escape 처리한 이후 줄바꿈 취급되는 곳이 있는지 확인해야 했다. 그렇다면, so-rule modify 명령어를 통해 manager sls파일에 쓰기를 진행하는 곳을 찾아야 했다. 다시, rulecat.py를 실행하기 전인 so-rule를 분석해야 한다.</p>\n<p>분석 결과... string 처리 중에는 개행으로 대체되는 곳이 없었고, 다른 부분에서 개행이 자동으로 들어갈 만한 구석이 있는지 찾아야만 했다. 그렇다면 파일 쓰기를 할 대 default로 개행이 들어가는지를 확인해야 하는데, manager sls 파일에 유일하게 쓰기를 하는 부분은 이곳이었다.</p>\n<p><a href=\"https://github.com/Security-Onion-Solutions/securityonion/blob/3839e5240127ac3c7b7659b2a270337f859dbf5a/salt/common/tools/sbin/so-rule#L108\"><em>so-rule line 108 참고</em></a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">write_pillar</span><span class=\"token punctuation\">(</span>pillar<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> content<span class=\"token punctuation\">:</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    sids <span class=\"token operator\">=</span> content<span class=\"token punctuation\">[</span><span class=\"token string\">'idstools'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sids'</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">if</span> sids<span class=\"token punctuation\">[</span><span class=\"token string\">'disabled'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n      <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sids<span class=\"token punctuation\">[</span><span class=\"token string\">'disabled'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span> sids<span class=\"token punctuation\">[</span><span class=\"token string\">'disabled'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n    <span class=\"token keyword\">if</span> sids<span class=\"token punctuation\">[</span><span class=\"token string\">'enabled'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n      <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sids<span class=\"token punctuation\">[</span><span class=\"token string\">'enabled'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span> sids<span class=\"token punctuation\">[</span><span class=\"token string\">'enabled'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n    <span class=\"token keyword\">if</span> sids<span class=\"token punctuation\">[</span><span class=\"token string\">'modify'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n      <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sids<span class=\"token punctuation\">[</span><span class=\"token string\">'modify'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span> sids<span class=\"token punctuation\">[</span><span class=\"token string\">'modify'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>pillar<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n      <span class=\"token keyword\">return</span> yaml<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">,</span> default_flow_style<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span>\n    print_err<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Could not open </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>pillar<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    sys<span class=\"token punctuation\">.</span>exit<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><code class=\"language-text\">yaml.dump()</code>가 <code class=\"language-text\">so-rule</code>에서 유일하게 파일을 쓰는 부분이다. <code class=\"language-text\">yaml.dump()</code> 이 함수에 대해 별도의 테스트를 진행해 보았더니, 너무 긴 string이 들어오면 자동으로 개행을 하는 옵션이 있었고, 무려 이것이 default였다. <code class=\"language-text\">yaml.dump()</code>에 개행하지 않는 옵션을 추가할 수는 있겠으나, 이는 즉 SO 소스에 변경이 불가피한 것이었다.</p>\n<h1>중간결론</h1>\n<p>sid로 검색해서 나온 rule 전문에 대해 덮어쓰기를 하는 방식을 SO 소스코드 변경 없이 구현하기 위해서는, manager sls 파일에 escape 처리된 <strong>rule을 직접 입력</strong>하는 것이 최선이다.</p>\n<h1>중간 해결책</h1>\n<p><code class=\"language-text\">so-rule</code> 코드를 일부 차용한 후 필요한 부분을 고치는 방법을 썼다.</p>\n<p>수정이 필요한 부분은 사실상 한 줄이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">yaml<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">,</span> default_flow_style<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>개행을 방지하기 위해 다음과 같은 옵션들을 줄 수 있다.</p>\n<ol>\n<li>\n<p>default_style 설정</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">yaml<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">,</span> default_flow_style<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> default_style<span class=\"token operator\">=</span><span class=\"token string\">'|'</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n<li>\n<p>width 설정</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">yaml<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">,</span> default_flow_style<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n</ol>\n<p>1은 검색했을 때 가장 많이 권고되는 방식이었다<a href=\"https://stackoverflow.com/questions/8640959/how-can-i-control-what-scalar-form-pyyaml-uses-for-my-data\">(참고한 stackoverflow 답변)</a>. 그러나 이런 방식으로 rule을 입력하면 단점이 있었다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token punctuation\">...</span>\n<span class=\"token key atrule\">idstools</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">...</span>\n  <span class=\"token key atrule\">sids</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">disabled</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">'0000001'</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">'0000002'</span>\n    <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">'0000003'</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">'0000004'</span>\n    <span class=\"token key atrule\">modify</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">|</span><span class=\"token punctuation\">-</span>\n      0000005 \"alert\\ ip\\ \\<span class=\"token punctuation\">[</span>1\\.117\\.107\\.241<span class=\"token punctuation\">,</span>1\\.117\\.113\\.235<span class=\"token punctuation\">,</span>1\\.117\\.142\\.123<span class=\"token punctuation\">,</span>1\\.117\\.155\\.76<span class=\"token punctuation\">,</span>1\\.117\\.233\\.118<span class=\"token punctuation\">,</span>1\\.117\\.87\\.94<span class=\"token punctuation\">,</span>1\\.12\\.220\\.225<span class=\"token punctuation\">,</span>1\\.13\\.5\\.215<span class=\"token punctuation\">,</span>1\\.14\\.101\\.60<span class=\"token punctuation\">,</span>1\\.14\\.162\\.37<span class=\"token punctuation\">,</span>1\\.14\\.170\\.161<span class=\"token punctuation\">,</span>1\\.14\\.63\\.99<span class=\"token punctuation\">,</span>1\\.14\\.72\\.158<span class=\"token punctuation\">,</span>1\\.15\\.112\\.113<span class=\"token punctuation\">,</span>1\\.15\\.119\\.209<span class=\"token punctuation\">,</span>1\\.15\\.155\\.17<span class=\"token punctuation\">,</span>1\\.15\\.48\\.27<span class=\"token punctuation\">,</span>1\\.15\\.94\\.178<span class=\"token punctuation\">,</span>1\\.212\\.197\\.134<span class=\"token punctuation\">,</span>1\\.234\\.80\\.51<span class=\"token punctuation\">,</span>1\\.234\\.80\\.65<span class=\"token punctuation\">,</span>1\\.6\\.52\\.114<span class=\"token punctuation\">,</span>1\\.9\\.78\\.242<span class=\"token punctuation\">,</span>101\\.176\\.32\\.93<span class=\"token punctuation\">,</span>101\\.32\\.127\\.191<span class=\"token punctuation\">,</span>101\\.32\\.141\\.93<span class=\"token punctuation\">,</span>101\\.33\\.232\\.244<span class=\"token punctuation\">,</span>101\\.34\\.0\\.215<span class=\"token punctuation\">,</span>101\\.34\\.103\\.153<span class=\"token punctuation\">,</span>101\\.34\\.211\\.195<span class=\"token punctuation\">,</span>101\\.34\\.246\\.169<span class=\"token punctuation\">,</span>101\\.34\\.67\\.139<span class=\"token punctuation\">,</span>101\\.34\\.69\\.51<span class=\"token punctuation\">,</span>101\\.35\\.181\\.230<span class=\"token punctuation\">,</span>101\\.35\\.19\\.119<span class=\"token punctuation\">,</span>101\\.35\\.219\\.249<span class=\"token punctuation\">,</span>101\\.35\\.232\\.12<span class=\"token punctuation\">,</span>101\\.35\\.252\\.124<span class=\"token punctuation\">,</span>101\\.35\\.255\\.83<span class=\"token punctuation\">,</span>101\\.35\\.98\\.237<span class=\"token punctuation\">,</span>101\\.42\\.0\\.60<span class=\"token punctuation\">,</span>101\\.42\\.154\\.35<span class=\"token punctuation\">,</span>101\\.42\\.234\\.70<span class=\"token punctuation\">,</span>101\\.42\\.237\\.207<span class=\"token punctuation\">,</span>101\\.42\\.47\\.78<span class=\"token punctuation\">,</span>101\\.43\\.155\\.178<span class=\"token punctuation\">,</span>101\\.43\\.19\\.142<span class=\"token punctuation\">,</span>101\\.43\\.226\\.18<span class=\"token punctuation\">,</span>101\\.43\\.5\\.247<span class=\"token punctuation\">,</span>101\\.43\\.67\\.29\\<span class=\"token punctuation\">]</span>\\ any\\ \\<span class=\"token punctuation\">-</span><span class=\"token punctuation\">></span>\\ \\$HOME_NET\\ any\\ \\(msg<span class=\"token punctuation\">:</span>\\\\\"ET\\ 3CORESec\\ Poor\\ Reputation\\ IP\\ group\\ 1\\\\\";\\ reference<span class=\"token punctuation\">:</span>url<span class=\"token punctuation\">,</span>blacklist\\.3coresec\\.net/lists/et\\<span class=\"token punctuation\">-</span>open\\.txt;\\ threshold<span class=\"token punctuation\">:</span>\\ type\\ limit<span class=\"token punctuation\">,</span>\\ track\\ by_src<span class=\"token punctuation\">,</span>\\ seconds\\ 3600<span class=\"token punctuation\">,</span>\\ count\\ 1;\\ classtype<span class=\"token punctuation\">:</span>misc\\<span class=\"token punctuation\">-</span>attack;\\ sid<span class=\"token punctuation\">:</span>0000005;\\ rev<span class=\"token punctuation\">:</span>855;\\ metadata<span class=\"token punctuation\">:</span>affected_product\\ Any<span class=\"token punctuation\">,</span>\\ attack_target\\ Any<span class=\"token punctuation\">,</span>\\ deployment\\ Perimeter<span class=\"token punctuation\">,</span>\\ tag\\ 3CORESec<span class=\"token punctuation\">,</span>\\ signature_severity\\ Major<span class=\"token punctuation\">,</span>\\ created_at\\ 2020_07_20<span class=\"token punctuation\">,</span>\\ updated_at\\ 2023_10_30;\\)\"</code></pre></div>\n<p>rule이 한줄로 처리되기는 하나 시작 지점에 <code class=\"language-text\">|-</code>와 함께 한번 줄바꿈처리 된다는 것이었다.\nrulecat.py로 넘어가서는 sid 하나당 단 한줄을 읽을 것이기 떄문에 이 방법이 나에게는 문제가 되었다.</p>\n<p>두번째 방법을 택하게 되었는데, 문제는 width를 얼마로 설정하느냐였다. rule이 상당히 길기 때문에 보통의 경우 1000자가 넘어갔다. 이는 <a href=\"https://github.com/OISF/suricata/blob/master-5.0.x/src/detect.h#L56\">suricata의 rule max length(=8192)</a>를 조사하여 반영하였다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">yaml<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>content<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">,</span> default_flow_style<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">8192</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h1>삽질 결과</h1>\n<p>위의 과정 모두가 어떻게 보면 suricata 내부적으로 룰 관리 커맨드 입력 시 이를 핸들링하기 위해 split하는 문자열을 입맛에 맞게 우회하기 위함이었다(ex. double quotes). 그런데 모든 방식의 우회 결과 결론은 아래와 같다.</p>\n<ol>\n<li>\n<p>double quotes는 당연히 우회해야 함. 그런데 double quotes만 우회시키면 bad arguments number가 뜸</p>\n</li>\n<li>\n<p>룰을 한 덩어리로 인식하지 못하는 문제로 보여, 추가적인 특수문자 우회를 함(<code class=\"language-text\">re.escape</code> 등. white space만 우회해 보기도 했다.)</p>\n</li>\n<li>\n<p>이런 후처리까지 할 경우, 별도의 오류는 생기지 않으나 우회된 룰 문자열을 인식하지 못함.</p>\n</li>\n</ol>\n<p>룰 전체를 인식시키고 그 전부를 대체시키고자 했으나, 룰 전체 인식이 불가해졌습니다.</p>\n<p>이후엔 편리하게 룰 disable 시키고 다시 등록시키는 방식으로 변경했습니다.</p>","categories":["troubleshooting"],"date":"November 02, 2023","description":"","id":"137a0e5f-0731-5d43-8238-e390e716c0d8","keywords":null,"slug":"/SecuriyOnion-so-rule-modify/","title":"Security onion: rule 전체 modify를 위한 삽질기","readingTime":{"text":"15 min read"}},"listingPagePath":"/blog/"}},"staticQueryHashes":["1094019748","460736852"],"slicesMap":{}}